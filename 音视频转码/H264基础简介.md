# H264基础简介

# 前言

H264是属于视频的编码层的标准格式，视频编码显然是为了压缩大小。
我们看下一个完全没压缩的视频数据大小。假设视频是高清（1280 * 720），每秒30帧，也就是每秒的数据

> 1280 * 720 *30 / 8(字节) /1024（KB）/1024(MB) = 3.11MB

那么90分钟的电影就要16.7GB，这个数据量显然在当前网络下是不现实的。

> **视频压缩的原理就是去除视频冗余部分，下面列举下**
> 1，时间冗余
> 时间冗余是序列图像(电视图像、动画)和语音数据中所经常包含的冗余。
> 图像序列中的两幅相邻的图像，后一幅图像与前一幅图像之间有较大的相关性，这反映为时间冗余。同理，在语言中，由于人在说话时发音的音频是一连续的渐变过程，而不是一个完全的在时间上独立的过程，因而存在时间冗余。
> 2，空间冗余
> 空间冗余是图像数据中经常存在的一种冗余。
> 在同一幅图像中，规则物体和规则背景(所谓规则是指表面颜色分布是有序的而不是杂乱无章的)的表面物理特性具有相关性，这些相关性的光成像结构在数字化图像中就表现为数据冗余。,
> 3，知识冗余
> 有许多图像的理解与某些基础知识有相当大的相关性,
> 例如：人脸的图像有固定的结构。比如，嘴的上方有鼻子。鼻子的上方有眼睛，鼻子位于正脸图像的中线上等等。这类规律性的结构可由先验知识相背景知识得到，我们称此类冗余为知识冗余。
> 4，结构冗余
> 有些图像从大域上看存在着非常强的纹理结构，例如布纹图像和草席图像，我们说它们在结构上存在冗余。
> 5，视觉冗余
> 人类视觉系统对于图像场的任何变化，并不是都能感知的。例如，对于图像的编码和解码处理时，由于压缩或量比截断引入了噪声而使图像发生了一些变化，如果这些变化不能为视觉所感知，则仍认为图像足够好。事实上人类视觉系统一般的分辨能力约为26灰度等级，而一般图像量化采用28灰度等级，这类冗余我们称为视觉冗余。
> 通常情况下，人类视觉系统对亮度变化敏感，而对色度的变化相对不敏感；在高亮度区，人眼对亮度变化敏感度下降。
> 对物体边缘敏感，内部区域相对不敏感；对整体结构敏感，而对内部细节相对不敏感。
> 6，信息熵冗余
> 信息熵是指一组数据所携带的信息量。它一般定义为：H =
> -∑pi×log2pi。其中N为码元个数，pi为码元yi发生的概率。由定义，为使单位数据量d接近于或等于H，应设d＝∑pi×b(yi)，其中b(yi)是分配给码元yi的比特数，理论上应取-log2pi。实际上在应用中很难估计出{Po，P1，…，PN—1}。因此一般取b(yo)＝b(y1)＝…＝b(yN—1)，例如，英文字母编码码元长为7比特，即b(yo)＝b(y1)＝…＝b(yN—1)＝7，这样所得的d必然大于H，由此带来的冗余称为信息墒冗余或编码冗余。

# H264原始码流结构

组成：
H264功能分为两层，VCL(视频编码层)和 NAL(网络提取层).

1. VCL：包括核心压缩引擎和块，宏块和片的语法级别定义，设计目标是尽可能地独立于网络进行高效的编码。
2. NAL：负责将VCL产生的比特字符串适配到各种各样的网络和多元环境中，覆盖了所有片级以上的语法级别。

VCL数据传输或者存储之前，会被映射到一个NALU中，H264数据包含一个个NALU。

> 一个NALU = 一组对应于视频编码的NALU头部信息 + 一个原始字节序列负荷(RBSP,Raw Byte Sequence Payload).

NALU结构

一个原始的NALU单元结构如下
[StartCode][NALU Header][NALU Payload]三部分。

> StartCode，是一个NALU单元开始，必须是00 00 00 01 或者00 00 01。

1. NAL Header

> 例如: 1 00 00 00 01 06: SEI信息
> 2 00 00 00 01 67: 0x67&0x1f = 0x07 :SPS
> 3 00 00 00 01 68: 0x68&0x1f = 0x08 :PPS
> 4 00 00 00 01 65: 0x65&0x1f = 0x05: IDR Slice

1. RBSP

RBSP序列举例

RBSP序列

# H264的码流分层结构

1. Slice(片)

可以看到NALU的主体是slice。
slice是H264提出的新概念，编码图片后切分高效整合而成。
一个图片有一个或者多个slice。通过NALU装载网络传输。

> 设置片的目的是为了限制误码的扩散和传输，编码片是项目独立的，一个片的预测不能以其他片中的宏块为参考图像。保证了某一片的预测误差不会传播到别的片。

一个slice同样包含Slice Header + Slice Data

slice有以下五种类型

(1) I -slice: slice的全部MB（宏块）都采用intra-prediction（帧内预测）的方式来编码；
(2) P-slice: slice中的MB（宏块）使用intra-prediction（帧内预测）和inter-prediction（帧间预测）的方式来编码，但每一个inter-prediction block最多只能使用一个移动向量；
(3) B-slice:与P-slice类似，但每一个inter-prediction block可以使用二个移动向量。B-slice的‘B’是指Bi-predictive（双向预测），除了可由前一张和后一张影像的I(或P、B)-slice外，也能从前二张不同影像的I(或P、B)-slice来做inter- prediction。
(4) SP-slice:即所谓的Switching P slice，为P-slice的一种特殊类型，用来串接两个不同bitrate的bitstream；
(5) SI-slice: 即所谓的Switching I slice，为I-slice的一种特殊类型，除了用来串接两个不同content的bitstream外，也可用来执行随机存取(random access)来达到网络VCR的功能

1. 宏块(Macroblock,MB)
   从上面结构图中可以看到片中包含宏块。那什么是宏块呢？

宏块是视频信息的主要承载者。一个编码图像通常划分为多个宏块组成.包含着每一个像素的亮度和色度信息。视频解码最主要的工作则是提供高效的方式从码流中获得宏块中像素阵列。

> 一个宏块 = 一个16*16的亮度像素 + 一个8×8Cb + 一个8×8Cr彩色像素块组成。(YCbCr 是属于 YUV 家族的一员,在YCbCr 中 Y 是指亮度分量，Cb 指蓝色色度分量，而 Cr 指红色色度分量)

宏块分类:

I宏块: 帧内预测

P宏块: 利用前帧作为参考进行帧内预测，一个帧内编码的宏块可进一步作宏块的分割

B宏块: 双向参考图像（前帧和后帧）进行帧内预测

**简单总结下帧和片和宏块的概念**
1帧 = 1个或n个片
1片 = n个宏块
1宏块 = 16x16yuv数据

slice结构

> mb_type 确定该 MB 是帧内或帧间(P 或 B)编码模式，确定该 MB 分割的尺寸
> mb_pred 确定帧内预测模式(帧内宏块)确定表 0 或表 1 参考图 像，和每一宏块分割的差分编码的运动矢量(帧间宏块，除 8×8 宏块分割的帧内 MB)
> sub_mb_pred (只对 8×8MB 分割的帧内 MB)确定每一子宏块的子宏 块分割，每一宏块分割的表 0 和/或表 1 的参考图象;每一 宏块子分割的差分编码运动矢量。
> coded_block_pattern 指出哪个 8×8 块(亮度和彩色)包 编码变换系数
> mb_qp_delta 量化参数的改变值
> esidual 预测后对应于残差图象取样的编码变换系数

# I,P,B,IDR帧，DTS和PTS，GOP

I帧: 帧内编码帧，I帧通常是每个GOP的第一帧，适度压缩，类似于图片jpg压缩一样的原理。大约可以得到6：1的压缩比。

P帧: 前向预测编码帧，通过图像序列前面已经编码帧的时间冗余信息压缩，称为预测帧，大约可以得到20：1的压缩比

B帧：双向预测内插编码帧,通过前帧和后帧的时间冗余信息压缩，也叫双向预测帧。大约可以得到50:1的压缩比

IDR帧: I帧的一种特殊帧，一个序列的第一个图像叫做 IDR 图像（立即刷新图像）

> 当解码器解码到 IDR 图像时，立即将参考帧队列清空，将已解码的数据全部输出或抛弃，重新查找参数集，开始一个新的序列。这样可以避免前一个序列出现重大错误的问题。

DTS: (Decode Time Stamp) 用于视频的解码序列
PTS: (Presentation Time Stamp)用于视频的显示序列。

DTS和PTS

GOP: （Group of Picture）两个I帧之间形成的一组图片，就是GOP。一般为编码器设置参数的时候，必须设置gop_size的值，表示两个I帧之间的帧数目，相对来说GOP_size设置越小，画面质量越好。但是相应的容量越大。

> 由于解码必须先获取到I帧，才能获得第一张图像，所以直播秒开的原理就是在CDN缓存一个GOP图片组，这样迅速解码出第一帧图。

